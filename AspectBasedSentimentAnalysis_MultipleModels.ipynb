{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import *\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "source_word2idx = {}\n",
    "target_word2idx = {}\n",
    "source_data = []\n",
    "source_loc_data = []\n",
    "target_data = []\n",
    "target_label = []\n",
    "\n",
    "final_list = []\n",
    "max_length = 0\n",
    "\n",
    "def read_data(file):\n",
    "    data_train_1 = pd.read_csv(file)\n",
    "    return data_train_1\n",
    "\n",
    "def read_and_process_data(data_train_1, sourceWord2idx, targetWord2idx):\n",
    "    global source_word2idx\n",
    "    global target_word2idx\n",
    "    source_word2idx = sourceWord2idx\n",
    "    target_word2idx = targetWord2idx\n",
    "    #parse_data(data_train_1)\n",
    "    #create_vocab(data_train_1)\n",
    "    data_train_1.apply(prepare_data,axis = 1)\n",
    "    return source_data, source_loc_data, target_data, target_label, max_length\n",
    "\n",
    "\n",
    "def split_data(data_train_1, train_size, test_size):\n",
    "    size = data_train_1.shape[0]\n",
    "    training_rows = math.ceil((train_size/100)*size)\n",
    "    testing_rows = size - training_rows\n",
    "    train_data = data_train_1.iloc[0:training_rows]\n",
    "    test_data = data_train_1.iloc[training_rows:]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def custom_tokenize(text):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    words = [word for word in tokens if word.isalnum()]\n",
    "    return words\n",
    "\n",
    "\n",
    "def parse_data(data_train_1):\n",
    "    data_train_1[' text'] = data_train_1[' text'].apply(lambda x: x.replace('[comma]',',').lower())\n",
    "    data_train_1[' text'] = data_train_1[' text'].apply(custom_tokenize)\n",
    "    data_train_1[' aspect_term'] = data_train_1[' aspect_term'].apply(lambda x: x.lower())\n",
    "    data_train_1[' aspect_term'] = data_train_1[' aspect_term'].apply(custom_tokenize)\n",
    "    data_train_1[' aspect_term'] = data_train_1[' aspect_term'].apply(lambda x:\" \".join(x))\n",
    "    return data_train_1\n",
    "\n",
    "\n",
    "def prepare_data(row):\n",
    "    global max_length\n",
    "    global source_word2idx\n",
    "    global target_word2idx\n",
    "    m = [source_word2idx[id] for id in row[' text']]\n",
    "    if len(m) == 2602:\n",
    "        print(row[' text'])\n",
    "    if len(m) > max_length:\n",
    "        max_length = len(m)\n",
    "    source_data.append(m)\n",
    "    t = [target_word2idx[row[' aspect_term']]]\n",
    "    target_data.append(t)\n",
    "    target_label.append(row[' class'])\n",
    "    g = get_pos(row)\n",
    "    datab = []\n",
    "    datab.append(m)\n",
    "    datab.append(g)\n",
    "    datab.append(t)\n",
    "    final_list.append(datab)\n",
    "\n",
    "\n",
    "def get_pos_old(row):\n",
    "    index = []\n",
    "    s_len = len(row[' text'])-1\n",
    "    p = row[' text'].copy()\n",
    "    #print('%s in %s: '%(row[' aspect_term'],row[' text']))\n",
    "    aspects = row[' aspect_term'].split(' ')\n",
    "    for aspect in aspects:\n",
    "        try:\n",
    "            if len(aspects)-1 > aspects.index(aspect):\n",
    "                a_i = [i for i,val in enumerate(row[' text']) if val==aspect]\n",
    "                #print(a_i)\n",
    "                \n",
    "                for a_id in a_i:\n",
    "                    try:\n",
    "                        if row[' text'][a_id+1] != aspects[aspects.index(aspect)+1]:\n",
    "                            a_i.remove(a_id)\n",
    "                    except:\n",
    "#                         print('a_i',a_i)\n",
    "#                         print('a_id',a_id)\n",
    "#                         print(a_i.index(a_id))\n",
    "                        a_i = a_i[:a_i.index(a_id)+1]\n",
    "#                         print('exception', a_i)\n",
    "                        break;\n",
    "    #             index.append(row[' text'].index(aspect))\n",
    "                index.extend(a_i)\n",
    "                #print(index)\n",
    "                for i in index:\n",
    "                    p[i] = s_len\n",
    "            else:\n",
    "                index.append(row[' text'].index(aspect))\n",
    "                p[row[' text'].index(aspect)] = s_len\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        for i in range(index[0]):\n",
    "#             p[i] = index[0] - i\n",
    "            p[i] = s_len - index[0] + i\n",
    "        v = s_len\n",
    "        for i in range(index[len(index)-1],len(p)):\n",
    "            #p[i] = i - index[len(index)-1]\n",
    "            if i == index[len(index)-1]:\n",
    "                p[i] = v\n",
    "            else:    \n",
    "                p[i] = v - 1\n",
    "                v = v-1\n",
    "            \n",
    "        #print(p)\n",
    "    except Exception as e: \n",
    "#         print(e)\n",
    "#         print(p)\n",
    "#         print('exception caught')\n",
    "#         print('%s,%s'%(row[' text'],row[' aspect_term']))\n",
    "        p = [0 for i in row[' text']]\n",
    "#         print(p)\n",
    "    #print(source_loc_data)\n",
    "    source_loc_data.append(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def get_pos(row):\n",
    "    index = []\n",
    "    s_len = len(row[' text'])-1\n",
    "    p = row[' text'].copy()\n",
    "    #print('%s in %s: '%(row[' aspect_term'],row[' text']))\n",
    "    aspects = row[' aspect_term'].split(' ')\n",
    "    for aspect in aspects:\n",
    "        try:\n",
    "            if len(aspects)-1 > aspects.index(aspect):\n",
    "                a_i = [i for i,val in enumerate(row[' text']) if val==aspect]\n",
    "                try:\n",
    "                    for a_id in a_i:\n",
    "                        if row[' text'][a_id+1] != aspects[aspects.index(aspect)+1]:\n",
    "                            a_i.remove(a_id)\n",
    "                except:\n",
    "                    pass\n",
    "    #             index.append(row[' text'].index(aspect))\n",
    "                index.extend(a_i[0])\n",
    "            else:\n",
    "                index.append(row[' text'].index(aspect))\n",
    "            p[row[' text'].index(aspect)] = s_len\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        for i in range(index[0]):\n",
    "#             p[i] = index[0] - i\n",
    "            p[i] = s_len - index[0] + i\n",
    "        v = s_len\n",
    "        for i in range(index[len(index)-1],len(p)):\n",
    "            #p[i] = i - index[len(index)-1]\n",
    "            if i == index[len(index)-1]:\n",
    "                p[i] = v\n",
    "            else:    \n",
    "                p[i] = v - 1\n",
    "                v = v-1\n",
    "            \n",
    "        #print(p)\n",
    "    except Exception as e: \n",
    "#         print(e)\n",
    "#         print(p)\n",
    "#         print('exception caught')\n",
    "#         print('%s,%s'%(row[' text'],row[' aspect_term']))\n",
    "        p = [0 for i in row[' text']]\n",
    "#         print(p)\n",
    "    source_loc_data.append(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "def create_vocab(data_train_1):\n",
    "    source_word2idx = {'<pad>': 0}\n",
    "    target_word2idx = {}\n",
    "    for words in data_train_1[' text']:\n",
    "        for word in words:\n",
    "            if word not in source_word2idx:\n",
    "                source_word2idx[word] = len(source_word2idx)\n",
    "\n",
    "    for words in data_train_1[' aspect_term']:\n",
    "        if words not in target_word2idx:\n",
    "            target_word2idx[words] = len(target_word2idx)\n",
    "    return source_word2idx, target_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/data_2_train.csv'\n",
    "#train_file = 'data/data_2_train.csv'\n",
    "\n",
    "data = read_data(train_file)\n",
    "parsed_data = parse_data(data)\n",
    "source_word2idx, target_word2idx = create_vocab(parsed_data)\n",
    "\n",
    "#trainData, testData = process_data.split_data(parsed_data, 80, 20)\n",
    "train_data = read_and_process_data(parsed_data, source_word2idx, target_word2idx)\n",
    "#test_data = process_data.read_and_process_data(testData, source_word2idx, target_word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sen_max_len:  70\n",
      "(3602, 3, 70)\n",
      "(3602, 210)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x1_list, x2_list, x3_list = list(), list(), list()\n",
    "example_list = list()\n",
    "\n",
    "sen_max_len = train_data[4]\n",
    "print(\"sen_max_len: \",sen_max_len)\n",
    "\n",
    "for i in range(len(train_data[0])):\n",
    "    x1, x2, x3 = list(), list(), list()\n",
    "    \n",
    "    x1.extend(train_data[0][i])\n",
    "    if len(x1) < sen_max_len:\n",
    "        for _ in range(sen_max_len - len(x1)):\n",
    "            x1.append(0)\n",
    "    \n",
    "    x2.extend(train_data[1][i])\n",
    "    if len(x2) < sen_max_len:\n",
    "        for _ in range(sen_max_len - len(x2)):\n",
    "            x2.append(0)\n",
    "            \n",
    "    x3.extend(train_data[2][i])\n",
    "    for j in range(len(x1) - 1):\n",
    "        x3.append(x3[0])\n",
    "    for k in range(sen_max_len - len(x3)):\n",
    "        x3.append(0)\n",
    "    \n",
    "    example = list()\n",
    "    example.append(x1)\n",
    "    example.append(x2)\n",
    "    example.append(x3)\n",
    "    #print(\"example: \",example)\n",
    "    example_list.append(example)\n",
    "\n",
    "len(example_list)\n",
    "\n",
    "final_array = np.array(example_list)\n",
    "print(final_array.shape)\n",
    "\n",
    "nsamples, nx, ny = final_array.shape\n",
    "feature_vector = final_array.reshape((nsamples,nx*ny))\n",
    "print(feature_vector.shape)\n",
    "labels = train_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3602"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([805, 2164, 633])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels).keys() # equals to list(set(words))\n",
    "# counts the elements' frequency\n",
    "Counter(labels).values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, 2164), (0, 2164), (1, 2164)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = SMOTE().fit_sample(feature_vector, labels)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5193, 210)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1731, 1730, 1732])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_labels).keys() # equals to list(set(words))\n",
    "# counts the elements' frequency\n",
    "Counter(train_labels).values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5193, 210)\n",
      "(5193,)\n",
      "(1299, 210)\n",
      "(1299,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_vectors.shape)\n",
    "print(test_labels.shape)\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "X = train_vectors\n",
    "y = train_labels\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "#print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(X.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5193, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.shape\n",
    "train_vectors.shape[0]\n",
    "train_X = np.zeros(shape=(train_vectors.shape[0],50))\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "111.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(train_vectors.shape[0]):\n",
    "    for j in range(50):\n",
    "        # print(\"indices [\",j,\"]: \",indices[j], \" train_vectors[i][indices[j]]:\",train_vectors[i][indices[j]])\n",
    "        train_X[i][j] = train_vectors[i][indices[j]]\n",
    "        \n",
    "print(\"***************************\")  \n",
    "print(train_X[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RFR: \n",
      "\n",
      "scores:  [0.75047985 0.73076923 0.78805395 0.78612717 0.76685934 0.80539499\n",
      " 0.74373796 0.73410405 0.7495183  0.74759152]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.78      0.78      0.78       433\n",
      "          0       0.79      0.78      0.79       432\n",
      "          1       0.75      0.76      0.76       434\n",
      "\n",
      "avg / total       0.77      0.77      0.77      1299\n",
      "\n",
      "Overall accuracy:  0.7744418783679754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFR\n",
    "#10,20,50,80\n",
    "n_estimators = [100,200,500]\n",
    "rfr = RFR(n_estimators=100,random_state=0)\n",
    "\n",
    "print(\"Results for RFR: \")\n",
    "print()\n",
    "\n",
    "rfr_scores = cross_val_score(rfr, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', rfr_scores)\n",
    "\n",
    "rfr.fit(train_vectors,train_labels)\n",
    "y_pred = rfr.predict(test_vectors) \n",
    "\n",
    "rfr_accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Overall accuracy: \",rfr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for DecisionTreeClassifier: \n",
      "\n",
      "scores:  [0.75047985 0.73076923 0.78805395 0.78612717 0.76685934 0.80539499\n",
      " 0.74373796 0.73410405 0.7495183  0.74759152]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.63      0.63       433\n",
      "          0       0.65      0.68      0.67       432\n",
      "          1       0.66      0.65      0.66       434\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1299\n",
      "\n",
      "Overall accuracy:  0.651270207852194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)\n",
    "print(\"Results for DecisionTreeClassifier: \")\n",
    "print()\n",
    "rfr_scores = cross_val_score(rfr, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', rfr_scores)\n",
    "\n",
    "dt_clf.fit(train_vectors,train_labels)\n",
    "y_pred = dt_clf.predict(test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Overall accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [0.66410749 0.65576923 0.69171484 0.68400771 0.68786127 0.68208092\n",
      " 0.64547206 0.66859345 0.68978805 0.67244701]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.68      0.84      0.75       433\n",
      "          0       0.68      0.89      0.77       432\n",
      "          1       0.81      0.39      0.53       434\n",
      "\n",
      "avg / total       0.73      0.70      0.68      1299\n",
      "\n",
      "Overall accuracy:  0.7036181678214011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(knn, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', scores)\n",
    "\n",
    "knn.fit(train_vectors, train_labels)\n",
    "y_pred = knn.predict(test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Overall accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:  [0.3915547  0.40961538 0.39691715 0.39306358 0.41811175 0.39884393\n",
      " 0.39691715 0.39884393 0.41040462 0.39884393]\n",
      "classifier_svc_accuracy:  0.4095458044649731\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.90      0.10      0.19       433\n",
      "          0       0.92      0.13      0.23       432\n",
      "          1       0.36      0.99      0.53       434\n",
      "\n",
      "avg / total       0.73      0.41      0.32      1299\n",
      "\n",
      "Overall accuracy:  0.4095458044649731\n"
     ]
    }
   ],
   "source": [
    "svc_classifier = svm.SVC(C = 100)\n",
    "\n",
    "classifier_svc_scores = cross_val_score(svc_classifier, train_vectors, train_labels, cv=10)  \n",
    "print('scores: ', classifier_svc_scores)\n",
    "\n",
    "svc_classifier.fit(train_vectors, train_labels)\n",
    "prediction_svc = svc_classifier.predict(test_vectors)\n",
    "\n",
    "classifier_svc_accuracy = accuracy_score(test_labels, prediction_svc)\n",
    "print('classifier_svc_accuracy: ', classifier_svc_accuracy)\n",
    "\n",
    "print(\"\")\n",
    "print(classification_report(test_labels, prediction_svc))\n",
    "print(\"Overall accuracy: \",classifier_svc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7859892224788299\n",
      "0.7359507313317937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('rfr', rfr), ('knn', knn), ('dt_clf', dt_clf)], voting='hard')\n",
    "eclf1 = eclf1.fit(train_vectors, train_labels)\n",
    "eclf1_pred = eclf1.predict(test_vectors)\n",
    "eclf1_accuracy_score = accuracy_score(test_labels, eclf1_pred)\n",
    "print(eclf1_accuracy_score)\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('rfr', rfr), ('knn', knn), ('dt_clf', dt_clf)], voting='soft')\n",
    "eclf2 = eclf2.fit(train_vectors, train_labels)\n",
    "eclf2_pred = eclf2.predict(test_vectors)\n",
    "eclf2_accuracy_score = accuracy_score(test_labels, eclf2_pred)\n",
    "print(eclf2_accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
